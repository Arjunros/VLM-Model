# **AI-Powered Autonomous Delivery Robot** ðŸš€ðŸ¤–

### **Integrating ROS2 with Vision-Language Models (VLM) for Intelligent Navigation & Interaction**

This project enhances an **autonomous delivery robot** by combining **ROS2, computer vision, and AI-powered natural language processing**. Using **Ollamaâ€™s LLaVA**, the robot can **see, understand, and respond** to its environment in real-time, enabling advanced human-robot interaction.

## **ðŸš€ Features**
âœ… **ROS2-Based Autonomy** â€“ Uses **Nav2, SLAM, and path planning** for efficient delivery.  
âœ… **AI-Powered Perception** â€“ Real-time **object detection and scene understanding** with a **vision-language model (VLM)**.  
âœ… **Voice-Controlled Commands** â€“ Interact with the robot via speech for seamless operation.  
âœ… **Live Video Processing** â€“ Captures and analyzes surroundings using **OpenCV & LLaVA**.  
âœ… **Natural Language Responses** â€“ The robot can answer questions about its environment and tasks.  

## **ðŸ›  Tech Stack**
- **ROS2** (Navigation, SLAM, Path Planning)
- **Ollama (LLaVA)** â€“ Vision-Language Model
- **OpenCV** â€“ Real-time video processing
- **SpeechRecognition & Pyttsx3** â€“ Voice interaction
- **Jetson Orin Nano** â€“ Hardware acceleration
